{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 성능 검증을 위한, 검증데이터 분리\n",
    "모델의 성능을 검증하는 것은 중요합니다<br>\n",
    "단순히 학습 - 테스트 데이터 분리해서 한번의 테스트를 진행하기보다는, 다수의 데이터셋으로 구분하여 평균정확도를 검증합니다. <br>\n",
    "다음의 방법을 통해 데이터셋을 확보하여 진행합니다\n",
    "- KFold 를 통한 데이터 분리\n",
    "- GridSearchCV를 통한 하이퍼파라미터튜닝 및 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFOLD 통한 데이터 분리\n",
    "train_test_split이 아닌, KFold를 통해 데이터셋을 구분합니다.<br>\n",
    "검증을 위해 k개의 샘플 데이터셋을 구성하므로 (n_split을 통해 셋팅)\n",
    "GridSearchCV처럼 검증효과를 볼 수 있습니다\n",
    "\n",
    "### KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 풀이 1 . np로 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter : 1번째 \n",
      " 교차검증 정확도 : 1.0, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 2번째 \n",
      " 교차검증 정확도 : 1.0, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 3번째 \n",
      " 교차검증 정확도 : 0.9, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 4번째 \n",
      " 교차검증 정확도 : 0.9333, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 5번째 \n",
      " 교차검증 정확도 : 0.7333, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "5 fold 검증 평균정확도 : 0.9133\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 전체 데이터 확보\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "label_ = iris.target\n",
    "\n",
    "# 검증 데이터셋 객체 셋팅\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "\n",
    "\n",
    "# 모델생성\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "n_iter = 0\n",
    "for train_idx, test_idx in kfold.split(data):\n",
    "    X_train, X_test = data[train_idx], data[test_idx]\n",
    "    y_train, y_test = label_[train_idx], label_[test_idx]\n",
    "\n",
    "    # 학습 및 예측\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "\n",
    "    # 평가\n",
    "    acc = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "\n",
    "    print(f'n_iter : {n_iter}번째 \\n 교차검증 정확도 : {acc}, 학습 데이터 크기 : {train_size}, 테스트 데이터 크기 : {test_size} ')\n",
    "    print(\"*************************************************\")\n",
    "    print()\n",
    "    cv_accuracy.append(acc)\n",
    "\n",
    "# 평균검증정확도 계산\n",
    "print(f'{n_iter} fold 검증 평균정확도 : {np.mean(cv_accuracy):.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 풀이2. df로 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter : 1번째 \n",
      " 교차검증 정확도 : 1.0, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 2번째 \n",
      " 교차검증 정확도 : 1.0, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 3번째 \n",
      " 교차검증 정확도 : 0.8333, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 4번째 \n",
      " 교차검증 정확도 : 0.9333, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 5번째 \n",
      " 교차검증 정확도 : 0.8, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "5 fold 검증 평균정확도 : 0.9133\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 전체 데이터 확보\n",
    "iris = load_iris()\n",
    "df =pd.DataFrame(data = iris.data, columns= iris.feature_names)\n",
    "df['label'] = iris.target\n",
    "\n",
    "# 검증 데이터셋 객체 셋팅\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "\n",
    "\n",
    "# 모델생성\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "n_iter = 0\n",
    "for train_idx, test_idx in kfold.split(df):\n",
    "    X_train, X_test = df.loc[train_idx, df.columns.difference(['label'])], df.loc[test_idx, df.columns.difference(['label']) ]\n",
    "    y_train, y_test = df.loc[train_idx, 'label'], df.loc[test_idx, 'label']\n",
    "\n",
    "    # 학습 및 예측\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "\n",
    "    # 평가\n",
    "    acc = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "\n",
    "    print(f'n_iter : {n_iter}번째 \\n 교차검증 정확도 : {acc}, 학습 데이터 크기 : {train_size}, 테스트 데이터 크기 : {test_size} ')\n",
    "    print(\"*************************************************\")\n",
    "    print()\n",
    "    cv_accuracy.append(acc)\n",
    "\n",
    "# 평균검증정확도 계산\n",
    "print(f'{n_iter} fold 검증 평균정확도 : {np.mean(cv_accuracy):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StratifiedKFold\n",
    "종속변수 (타겟값)이 다중분류인 경우는 stratifiedkfold를 적용하여 샘플링을 하면 보다 정확한 결과를 얻을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter : 1번째 \n",
      " 교차검증 정확도 : 0.9667, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 2번째 \n",
      " 교차검증 정확도 : 0.9667, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 3번째 \n",
      " 교차검증 정확도 : 0.9, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 4번째 \n",
      " 교차검증 정확도 : 1.0, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "n_iter : 5번째 \n",
      " 교차검증 정확도 : 1.0, 학습 데이터 크기 : 120, 테스트 데이터 크기 : 30 \n",
      "*************************************************\n",
      "\n",
      "5 fold 검증 평균정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 전체 데이터 확보\n",
    "iris = load_iris()\n",
    "df =pd.DataFrame(data = iris.data, columns= iris.feature_names)\n",
    "df['label'] = iris.target\n",
    "\n",
    "# 검증 데이터셋 객체 셋팅\n",
    "skfold = StratifiedKFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "\n",
    "\n",
    "# 모델생성\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "n_iter = 0\n",
    "for train_idx, test_idx in skfold.split(df, df['label']):\n",
    "    X_train, X_test = df.loc[train_idx, df.columns.difference(['label'])], df.loc[test_idx, df.columns.difference(['label']) ]\n",
    "    y_train, y_test = df.loc[train_idx, 'label'], df.loc[test_idx, 'label']\n",
    "\n",
    "    # 학습 및 예측\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "\n",
    "    # 평가\n",
    "    acc = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "\n",
    "    print(f'n_iter : {n_iter}번째 \\n 교차검증 정확도 : {acc}, 학습 데이터 크기 : {train_size}, 테스트 데이터 크기 : {test_size} ')\n",
    "    print(\"*************************************************\")\n",
    "    print()\n",
    "    cv_accuracy.append(acc)\n",
    "\n",
    "# 평균검증정확도 계산\n",
    "print(f'{n_iter} fold 검증 평균정확도 : {np.mean(cv_accuracy):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "train_test_split 된 데이터에 대하여, 교차검증과 최적의 하이퍼파라미터* 튜닝을 동시에 하기위해, GridSearchCV를 활용합니다. <br>\n",
    "- 하이퍼파라미터 : 모델에 적용/변경하는 셋팅 값으로, 데이터 형태에 따라 모델의 성능을 높이기 위해서 최적의 값을 찾아줄 필요가 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.675000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.675000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.916667                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.916667                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.950000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.933333                2   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.675              0.675              0.675  \n",
       "1              0.675              0.675              0.675  \n",
       "2              0.900              0.900              0.950  \n",
       "3              0.900              0.900              0.950  \n",
       "4              1.000              0.900              0.950  \n",
       "5              0.950              0.900              0.950  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 전체 데이터 확보\n",
    "iris = load_iris()\n",
    "df =pd.DataFrame(data = iris.data, columns= iris.feature_names)\n",
    "df['label'] = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[df.columns.difference(['label'])], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 검증할 하이퍼파라미터 그리드 생성\n",
    "grid_parameters = {'max_depth':[1,2,3],\n",
    "'min_samples_split':[2,3]\n",
    "}\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "grid_clf = GridSearchCV(clf, param_grid= grid_parameters, cv=3, refit = True)\n",
    "#refit=True 가 default로, 가장 성능 높은 값으로 선택\n",
    "\n",
    "grid_clf.fit(X_train, y_train) # 학습\n",
    "\n",
    "score_df = pd.DataFrame(grid_clf.cv_results_)\n",
    "score_df[['params','mean_test_score', 'rank_test_score',\n",
    "       'split0_test_score', 'split1_test_score', 'split2_test_score'\n",
    "       ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최고 정확도 : 0.9500\n",
      "테스트세트 정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 최적 파라미터 적용\n",
    "estimator = grid_clf.best_estimator_\n",
    "print(f'GridSearchCV 최고 정확도 : {grid_clf.best_score_:.4f}')\n",
    "# 테스트세트 예측 및 검증\n",
    "pred = estimator.predict(X_test)\n",
    "print(f'테스트세트 정확도 : {accuracy_score(y_test,pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4395888be403c58de61e9eb932f3da5d54821f847dc0ca6e361f0068678bfd78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
